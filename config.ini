[Setup]
; redundant
poly_coeffs_range=3
; redundant
ulcd_range=3
; the target constant
const=e
; normal is a_n = A0+A1*n+A2*n^2+A3*n^3+...Ak*n^k    indexed is A0*n^k+A1*(n-1)^k+A2*(n-2)^k+A3*(n-3)^k+...+Ak*(n-k)^k
ab_polys_type=normal
; redundant
a_poly_size=6
; redundant
b_poly_size=6
; redundant
a_interlace=1
; redundant
b_interlace=1
; printing slow convergence cases that we thought should be fast (can be identified by the discriminant)
print_surprising_nonexp_contfracs=False
; just for hashtable - not looking for clicks
gen_hashtable_only=truerequi
; for example: [[[],[]],[[],[],[]],[[],[],[],[]],[[],[]]] 4-interlace with degrees of 2,3,4,2 . [a b] means running on coefficients between a to b-1
;a_coeffs_range=[[[0, 4], [0, 4], [0, 4], [0, 4], [0, 4], [0, 4]]]
;b_coeffs_range=[[[0, 4], [0, 4], [0, 4], [0, 4], [0, 4], [0, 4]]]
a_coeffs_range=[[[0, 4], [0, 4], [0, 4], [0, 4], [0, 4]]]
b_coeffs_range=[[[0, 4], [0, 4], [0, 4], [0, 4], [0, 4]]]

;lhs_params=[3, 3, 3, 3]
; constant number of iterations. probably enough for the exponential converging cases. problematic for when the discriminant is <=0 (that may create false entries in the hashtables that will be filtered after clicks)
hashtable_num_of_iterations=300
; number of digits saved in the hashtable
hashtable_precision=15
;lhs_type=ulcd
; the ratio of polynoms on the left hand side
lhs_type=rationalfunc
; same parsing as the ab polynomials although here there is no need for interlacing
lhs_params=[[[0, 7], [0, 7], [0, 7]], [[0, 7], [0, 7], [0, 7]]]
;lhs_params=[[[0, 2], [0, 2], [0, 2]], [[0, 2], [0, 2], [0, 2]]]
; the subgroup of postprocessing functions
postproc_funcs_filter=["safe_inverse", "lambda x: x", "lambda x: x**2", "lambda x: safe_inverse(x**2)", "safe_sqrt", "lambda x: safe_inverse(safe_sqrt(x))"]
; for some constants we have an index telling which one (constants with no index, like e and pi, ignore this)
i=3

; options for hastable_file_opeartion: use, generate, expand
; generate will create a new file even if using an existing name (v2, v3,...)
; expand will first load the most updated file (v_latest) and then add the new entries and save to v_latest+1
; use will load the v_latest and use it (no generation of hash table)
hashtable_file_operation=generate
; file name without the v_number part
hashtable_file = hashtable_e_to_join.pkl
;hashtable_file = hash_table.pkl;